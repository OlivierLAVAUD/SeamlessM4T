#!/usr/bin/env python3
"""
SeamlessM4T T2TT - Text-to-Text Translation
Specialized text translation with auto-GPU detection

Based on: https://huggingface.co/docs/transformers/model_doc/seamless_m4t_v2
"""

import gradio as gr
import torch
import logging
from transformers import AutoProcessor, SeamlessM4Tv2Model
import numpy as np
import os
from datetime import datetime

# Configuration
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SeamlessM4T_T2TT:
    """Text translation (Text-to-Text)"""
    
    # Langues supportÃ©es par le modÃ¨le SeamlessM4T v2 pour T2TT
    # Selon la documentation, T2TT supporte les mÃªmes langues que S2TT
    T2TT_SUPPORTED_LANGUAGES = {
        "arb": "Arabic",
        "ben": "Bengali",
        "cat": "Catalan",
        "ces": "Czech",
        "cmn": "Mandarin Chinese",
        "cym": "Welsh",
        "dan": "Danish",
        "deu": "German",
        "eng": "English",
        "est": "Estonian",
        "fin": "Finnish",
        "fra": "French",
        "hin": "Hindi",
        "ind": "Indonesian",
        "ita": "Italian",
        "jpn": "Japanese",
        "kan": "Kannada",
        "kor": "Korean",
        "mlt": "Maltese",
        "nld": "Dutch",
        "pes": "Western Persian",
        "pol": "Polish",
        "por": "Portuguese",
        "ron": "Romanian",
        "rus": "Russian",
        "slk": "Slovak",
        "spa": "Spanish",
        "swe": "Swedish",
        "swh": "Swahili",
        "tam": "Tamil",
        "tel": "Telugu",
        "tgl": "Tagalog",
        "tha": "Thai",
        "tur": "Turkish",
        "ukr": "Ukrainian",
        "urd": "Urdu",
        "uzn": "Northern Uzbek",
        "vie": "Vietnamese"
    }
    
    # Toutes les langues supportÃ©es par SeamlessM4T (pour rÃ©fÃ©rence)
    ALL_SUPPORTED_LANGUAGES = {
        "afr": "Afrikaans", "amh": "Amharic", "ara": "Arabic", "arb": "Arabic (Modern Standard)",
        "asm": "Assamese", "aze": "Azerbaijani", "bel": "Belarusian", "ben": "Bengali",
        "bos": "Bosnian", "bul": "Bulgarian", "cat": "Catalan", "ceb": "Cebuano",
        "ces": "Czech", "ckb": "Central Kurdish", "cmn": "Mandarin Chinese", "cym": "Welsh",
        "dan": "Danish", "deu": "German", "ell": "Greek", "eng": "English",
        "est": "Estonian", "eus": "Basque", "fin": "Finnish", "fra": "French",
        "gaz": "West Central Oromo", "gle": "Irish", "glg": "Galician", "guj": "Gujarati",
        "heb": "Hebrew", "hin": "Hindi", "hrv": "Croatian", "hun": "Hungarian",
        "hye": "Armenian", "ibo": "Igbo", "ind": "Indonesian", "isl": "Icelandic",
        "ita": "Italian", "jav": "Javanese", "jpn": "Japanese", "kan": "Kannada",
        "kat": "Georgian", "kaz": "Kazakh", "kea": "Kabuverdianu", "khk": "Halh Mongolian",
        "khm": "Khmer", "kir": "Kyrgyz", "kor": "Korean", "lao": "Lao",
        "lit": "Lithuanian", "ltz": "Luxembourgish", "lug": "Ganda", "luo": "Luo",
        "lvs": "Standard Latvian", "mai": "Maithili", "mal": "Malayalam", "mar": "Marathi",
        "mkd": "Macedonian", "mlt": "Maltese", "mni": "Meitei", "mya": "Burmese",
        "nld": "Dutch", "nno": "Norwegian Nynorsk", "nob": "Norwegian BokmÃ¥l",
        "npi": "Nepali", "nya": "Nyanja", "oci": "Occitan", "ory": "Odia",
        "pan": "Punjabi", "pbt": "Southern Pashto", "pes": "Western Persian",
        "pol": "Polish", "por": "Portuguese", "ron": "Romanian", "rus": "Russian",
        "slk": "Slovak", "slv": "Slovenian", "sna": "Shona", "snd": "Sindhi",
        "som": "Somali", "spa": "Spanish", "srp": "Serbian", "swe": "Swedish",
        "swh": "Swahili", "tam": "Tamil", "tel": "Telugu", "tgk": "Tajik",
        "tgl": "Tagalog", "tha": "Thai", "tur": "Turkish", "ukr": "Ukrainian",
        "urd": "Urdu", "uzb": "Uzbek", "uzn": "Northern Uzbek", "vie": "Vietnamese",
        "xho": "Xhosa", "yid": "Yiddish", "yor": "Yoruba", "yue": "Cantonese",
        "zho": "Chinese", "zsm": "Standard Malay", "zul": "Zulu"
    }
    
    def __init__(self):
        """Initialisation avec auto-dÃ©tection GPU"""
        logger.info("ğŸ”‹ Initialisation de SeamlessM4T T2TT...")
        
        # Auto-dÃ©tection GPU/CPU
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"ğŸ”¥ Utilisation du device: {self.device}")
        
        # Chargement du modÃ¨le
        self._load_model()
        
        # Initialiser le compteur de requÃªtes pour la gestion mÃ©moire
        self.request_count = 0
        self.MAX_REQUESTS_BEFORE_CLEANUP = 5  # Nettoyer aprÃ¨s 5 requÃªtes
    
    def _cleanup_gpu_memory(self):
        """Nettoyer la mÃ©moire GPU de maniÃ¨re sÃ»re"""
        try:
            if self.device == "cuda" and torch.cuda.is_available():
                # Vider le cache CUDA
                torch.cuda.empty_cache()
                
                # Synchroniser pour s'assurer que le nettoyage est terminÃ©
                torch.cuda.synchronize()
                
                # VÃ©rifier la mÃ©moire disponible
                free_memory = torch.cuda.mem_get_info()[0] / 1024**3  # en Go
                logger.info(f"ğŸ§¹ MÃ©moire GPU nettoyÃ©e. Disponible: {free_memory:.1f} Go")
                
                return True
        except Exception as e:
            logger.warning(f"âš ï¸  Impossible de nettoyer la mÃ©moire GPU: {e}")
        return False
    
    def _load_model(self):
        """Chargement optimisÃ© du modÃ¨le sans avertissement sampling_rate"""
        try:
            logger.info("ğŸ”‹ Chargement du modÃ¨le SeamlessM4T pour T2TT...")
            
            # CrÃ©er le processeur pour T2TT
            self.processor = AutoProcessor.from_pretrained(
                "facebook/seamless-m4t-v2-large",
                use_fast=False
            )
            logger.info("âœ… Processeur chargÃ©")
            
            # Charger le modÃ¨le avec optimisation
            model_kwargs = {
                "torch_dtype": torch.float16 if self.device == "cuda" else torch.float32,
                "low_cpu_mem_usage": True
            }
            
            self.model = SeamlessM4Tv2Model.from_pretrained(
                "facebook/seamless-m4t-v2-large",
                **model_kwargs
            ).to(self.device)
            
            logger.info("âœ… ModÃ¨le chargÃ© avec succÃ¨s")
            
        except Exception as e:
            logger.error(f"âŒ Erreur de chargement: {e}")
            raise
    
    def translate_text(self, text: str, src_lang: str, tgt_lang: str) -> str:
        """Text translation (T2TT) with error handling"""
        try:
            # IncrÃ©menter le compteur de requÃªtes
            self.request_count += 1
            
            # Nettoyer la mÃ©moire GPU pÃ©riodiquement
            if self.device == "cuda" and self.request_count >= self.MAX_REQUESTS_BEFORE_CLEANUP:
                self._cleanup_gpu_memory()
                self.request_count = 0  # RÃ©initialiser le compteur
            
            # Validation
            if src_lang not in self.ALL_SUPPORTED_LANGUAGES:
                raise ValueError(f"Langue source non supportÃ©e: {src_lang}")
            if tgt_lang not in self.T2TT_SUPPORTED_LANGUAGES:
                supported_t2tt_langs = ", ".join(self.T2TT_SUPPORTED_LANGUAGES.keys())
                raise ValueError(f"Langue cible non supportÃ©e pour T2TT: {tgt_lang}. "
                               f"Langues supportÃ©es: {supported_t2tt_langs}")
            
            # Validation du texte
            if not text or not text.strip():
                raise ValueError("Le texte Ã  traduire ne peut pas Ãªtre vide")
            
            if len(text) > 10000:  # Limite pour Ã©viter les problÃ¨mes mÃ©moire
                logger.warning(f"âš ï¸  Texte trÃ¨s long ({len(text)} caractÃ¨res). DÃ©coupage en segments...")
                # DÃ©couper le texte en segments plus petits
                segment_length = 5000  # Environ 5000 caractÃ¨res par segment
                segments = [text[i:i+segment_length] for i in range(0, len(text), segment_length)]
                translated_segments = []
                
                for i, segment in enumerate(segments):
                    logger.info(f"Traitement segment {i+1}/{len(segments)}")
                    try:
                        segment_translation = self._translate_single_text(segment, src_lang, tgt_lang)
                        translated_segments.append(segment_translation)
                    except Exception as segment_error:
                        logger.error(f"âŒ Erreur de traduction du segment {i+1}: {segment_error}")
                        translated_segments.append(f"[ERREUR: {str(segment_error)}]")
                
                # Concatenation des traductions
                return " ".join(translated_segments)
            else:
                # Traitement normal pour les textes courts
                return self._translate_single_text(text, src_lang, tgt_lang)
            
        except Exception as e:
            logger.error(f"âŒ Erreur de traduction: {e}")
            # Toujours vider la mÃ©moire GPU en cas d'erreur
            self._cleanup_gpu_memory()
            raise
    
    def _translate_single_text(self, text: str, src_lang: str, tgt_lang: str) -> str:
        """Translation of a single text"""
        try:
            # PrÃ©parer les entrÃ©es pour le modÃ¨le (T2TT utilise text_inputs)
            inputs = self.processor(
                text=[text],
                src_lang=src_lang,
                return_tensors="pt"
            ).to(self.device)
            
            # GÃ©nÃ©rer la traduction
            with torch.no_grad():
                try:
                    # Pour T2TT avec SeamlessM4T v2, nous devons utiliser la bonne approche
                    # Selon la documentation, pour T2TT nous devons:
                    # 1. DÃ©sactiver la gÃ©nÃ©ration audio
                    # 2. Utiliser la tÃ¢che appropriÃ©e
                    output = self.model.generate(
                        **inputs,
                        tgt_lang=tgt_lang,
                        generate_speech=False  # DÃ©sactiver la gÃ©nÃ©ration audio
                    )
                except Exception as model_error:
                    error_msg = str(model_error)
                    if "not supported by this model" in error_msg:
                        start_idx = error_msg.find("in ") + 3
                        end_idx = error_msg.find(". Note that")
                        if start_idx > 0 and end_idx > 0:
                            supported_langs = error_msg[start_idx:end_idx].strip()
                            raise ValueError(f"Langue cible '{tgt_lang}' non supportÃ©e pour T2TT. "
                                           f"Langues supportÃ©es: {supported_langs}")
                    raise
            
            # Extraire le texte gÃ©nÃ©rÃ© pour T2TT
            # Selon la documentation SeamlessM4T v2, la sortie est un objet spÃ©cifique
            
            # Pour T2TT, la sortie devrait Ãªtre un objet avec les tokens de texte
            if hasattr(output, 'sequences'):
                # Cas 1: La sortie a un attribut 'sequences'
                generated_tokens = output.sequences
            elif isinstance(output, tuple):
                # Cas 2: La sortie est un tuple
                generated_tokens = output[0]
            elif hasattr(output, 'cpu'):
                # Cas 3: La sortie est un tensor
                generated_tokens = output.cpu()
            else:
                # Cas 4: Autre format
                generated_tokens = output
            
            # Convertir en texte
            try:
                # Utiliser batch_decode qui gÃ¨re les diffÃ©rents formats
                text = self.processor.tokenizer.batch_decode(
                    generated_tokens,
                    skip_special_tokens=True
                )
                
                # Prendre le premier Ã©lÃ©ment si c'est une liste
                if isinstance(text, list) and len(text) > 0:
                    text = text[0]
                elif isinstance(text, list):
                    text = ""
                
                logger.info(f"Translated text: {text}")
                return text
            except Exception as e:
                logger.error(f"Erreur de dÃ©codage: {e}")
                raise ValueError(f"Impossible de dÃ©coder la sortie: {e}")
            finally:
                # Toujours vider la mÃ©moire GPU aprÃ¨s le traitement
                if self.device == "cuda":
                    self._cleanup_gpu_memory()
                    
        except Exception as e:
            logger.error(f"âŒ Erreur de traduction textuelle: {e}")
            raise


class SeamlessT2TTApp:
    """Gradio interface for SeamlessM4T T2TT"""
    
    def __init__(self):
        self.t2tt = SeamlessM4T_T2TT()
        self.languages = self.t2tt.T2TT_SUPPORTED_LANGUAGES
    
    def t2tt_interface(self, text: str, src_lang: str, tgt_lang: str) -> str:
        """Interface for text translation"""
        try:
            translation_output = self.t2tt.translate_text(text, src_lang, tgt_lang)
            return translation_output
        except ValueError as e:
            error_msg = str(e)
            if len(error_msg) > 200:
                if "Langues supportÃ©es:" in error_msg:
                    start_idx = error_msg.find("Langues supportÃ©es:")
                    return error_msg[:start_idx + 20] + "... (voir logs)"
                else:
                    return error_msg[:200] + "..."
            return f"âŒ {error_msg}"
        except Exception as e:
            error_msg = str(e)
            if len(error_msg) > 200:
                return f"âŒ {error_msg[:200]}..."
            return f"âŒ Erreur inattendue: {error_msg}"
        finally:
            # Toujours vider la mÃ©moire GPU aprÃ¨s chaque requÃªte
            if hasattr(self.t2tt, '_cleanup_gpu_memory'):
                self.t2tt._cleanup_gpu_memory()
    
    def create_interface(self):
        """Create the Gradio interface"""
        
        with gr.Blocks(title="SeamlessM4T T2TT") as app:
            gr.Markdown("""
            # ğŸ“ SeamlessM4T Text-to-Text Translation (T2TT)
            Specialized text translation with auto-GPU detection
            
            **FonctionnalitÃ©s:**
            - ğŸ“ Texte vers Texte (T2TT)
            - ğŸ”¥ Auto-dÃ©tection GPU/CPU
            - ğŸŒ Support multilingue (36 langues)
            - ğŸ“„ Long text handling (automatic segmentation)
            - ğŸ§¹ Nettoyage automatique de la mÃ©moire GPU
            
            **Langues supportÃ©es pour T2TT:** Arabic, Bengali, Catalan, Czech, Mandarin, Welsh, Danish, German, English, Estonian, Finnish, French, Hindi, Indonesian, Italian, Japanese, Kannada, Korean, Maltese, Dutch, Persian, Polish, Portuguese, Romanian, Russian, Slovak, Spanish, Swedish, Swahili, Tamil, Telugu, Tagalog, Thai, Turkish, Ukrainian, Urdu, Uzbek, Vietnamese
            
            """)
            
            with gr.Row():
                t2tt_text = gr.Textbox(
                    label="Text to translate",
                    lines=5,
                    placeholder="Enter text to translate here..."
                )
            
            with gr.Row():
                t2tt_src_lang = gr.Dropdown(
                    choices=list(self.languages.keys()),
                    value="fra",
                    label="Langue source"
                )
                t2tt_tgt_lang = gr.Dropdown(
                    choices=list(self.languages.keys()),
                    value="eng",
                    label="Langue cible"
                )
            
            t2tt_btn = gr.Button("Translate text", variant="primary")
            t2tt_output = gr.Textbox(label="Translated text", lines=5)
            
            t2tt_btn.click(
                fn=self.t2tt_interface,
                inputs=[t2tt_text, t2tt_src_lang, t2tt_tgt_lang],
                outputs=t2tt_output
            )
            
            gr.Markdown("""
            ---
            ### Informations
            - **Device:** " + ("ğŸ”¥ GPU" if torch.cuda.is_available() else "â„ï¸ CPU") + ""
            - **ModÃ¨le:** facebook/seamless-m4t-v2-large
            - **DurÃ©e max par segment:** 5000 caractÃ¨res
            - **Nettoyage GPU:** AprÃ¨s 5 requÃªtes
            
            Â© 2024 SeamlessM4T T2TT
            """)
        
        return app
    
    def launch(self):
        """Lance l'application"""
        try:
            app = self.create_interface()
            app.launch(
                server_name="0.0.0.0",
                server_port=7869,  # Port diffÃ©rent des autres applications
                share=False
            )
        finally:
            # Nettoyer les ressources GPU Ã  la fin
            if hasattr(self.t2tt, '_cleanup_gpu_memory'):
                self.t2tt._cleanup_gpu_memory()
            logger.info("ğŸ§¹ Ressources GPU nettoyÃ©es Ã  la fin de l'application")


if __name__ == "__main__":
    try:
        logger.info("ğŸš€ Lancement de SeamlessM4T T2TT...")
        app = SeamlessT2TTApp()
        app.launch()
    except Exception as e:
        logger.error(f"Erreur fatale: {e}")
        # Nettoyer les ressources GPU en cas d'erreur fatale
        if 'app' in locals() and hasattr(app.t2tt, '_cleanup_gpu_memory'):
            app.t2tt._cleanup_gpu_memory()
        raise